{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter7 Descriptive Statistics and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 Wine Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 Customer Chum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Wine Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 描述性統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load statistics/wine_quality.py\n",
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols, glm\n",
    "\n",
    "\n",
    "# Read the data set into a pandas DataFrame\n",
    "wine = pd.read_csv('winequality-both.csv', sep=',', header=0)\n",
    "wine.columns = wine.columns.str.replace(' ', '_')\n",
    "print(wine.head())\n",
    "\n",
    "# Display descriptive statistics for all variables\n",
    "print(wine.describe())\n",
    "\n",
    "# Identify unique values\n",
    "print(sorted(wine.quality.unique()))\n",
    "\n",
    "# Calculate value frequencies\n",
    "print(wine.quality.value_counts())\n",
    "\n",
    "# Display descriptive statistics for quality by wine type\n",
    "print(wine.groupby('type')[['alcohol']].describe().unstack('type'))\n",
    "\n",
    "# Calculate specific quantiles\n",
    "print(wine.groupby('type')[['quality']].quantile([0.25, 0.75]).unstack('type'))\n",
    "\n",
    "# Calculate correlation matrix for all variables\n",
    "print(wine.corr())\n",
    "\n",
    "# Look at relationship between pairs of variables\n",
    "# Take a \"small\" sample of red and white wines for plotting\n",
    "def take_sample(data_frame, replace=False, n=200):\n",
    "\treturn data_frame.loc[np.random.choice(data_frame.index, replace=replace, size=n)]\t\n",
    "reds = wine.loc[wine['type']=='red', :]\n",
    "whites = wine.loc[wine['type']=='white', :]\n",
    "reds_sample = take_sample(wine.loc[wine['type']=='red', :])\n",
    "whites_sample = take_sample(wine.loc[wine['type']=='white', :])\n",
    "wine_sample = pd.concat([reds_sample, whites_sample])\n",
    "wine['in_sample'] = np.where(wine.index.isin(wine_sample.index), 1.,0.)\n",
    "\n",
    "reds_sample = reds.ix[np.random.choice(reds.index, 100)]\n",
    "whites_sample = whites.ix[np.random.choice(whites.index, 100)]\n",
    "wine_sample = pd.concat([reds_sample, whites_sample], ignore_index=True)\n",
    "\n",
    "print(wine['in_sample'])\n",
    "print(pd.crosstab(wine.in_sample, wine.type, margins=True))\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_style(\"darkgrid\", {\"legend.scatterpoints\": 0})\n",
    "pg = sns.PairGrid(wine_sample, hue=\"type\", hue_order=[\"red\", \"white\"], \\\n",
    "palette=dict(red=\"red\", white=\"white\"), hue_kws={\"marker\": [\"o\", \"s\"]}, vars=['quality', 'alcohol', 'residual_sugar'])\n",
    "pg.x = wine_sample.ix[wine_sample['type']=='red', 'quality']\n",
    "pg = pg.map_diag(plt.hist)\n",
    "pg.x = wine_sample.ix[wine_sample['type']=='white', 'quality']\n",
    "pg = pg.map_diag(plt.hist)\n",
    "pg = pg.map_offdiag(plt.scatter, edgecolor=\"black\", s=10, alpha=0.25)\n",
    "#plt.show()\n",
    "\n",
    "g = sns.pairplot(wine_sample, kind='reg', plot_kws={\"ci\": False, \"x_jitter\": 0.25, \"y_jitter\": 0.25}, \\\n",
    "hue='type', diag_kind='hist', diag_kws={\"bins\": 10, \"alpha\": 1.0}, palette=dict(red=\"red\", white=\"white\"), \\\n",
    "markers=[\"o\", \"s\"], vars=['quality', 'alcohol', 'residual_sugar'])\n",
    "sns.set_style({'legend.frameon': True,'legend.numpoints': 0,'legend.scatterpoints': 0})\n",
    "wine_all_plot = sns.pairplot(wine, kind='reg', hue='type', palette=dict(red=\"red\", white=\"white\"), markers=[\"o\", \"s\"], vars=['quality', 'alcohol', 'residual_sugar'])\n",
    "wine_sample_plot = sns.pairplot(wine_sample, kind='reg', hue='type', palette=dict(red=\"red\", white=\"white\"), markers=[\"o\", \"s\"], vars=['quality', 'alcohol', 'residual_sugar'])\n",
    "\n",
    "wine['ln_fixed_acidity'] = np.log(wine.ix[:, 'fixed_acidity'])\n",
    "sns.distplot(wine.ix[:, 'fixed_acidity'])\n",
    "sns.distplot(wine.ix[:, 'ln_fixed_acidity'])\n",
    "print(g)\n",
    "plt.suptitle('Histograms and Scatter Plots of Quality, Alcohol, and Residual Sugar', fontsize=14, \\\n",
    "\t\thorizontalalignment='center', verticalalignment='top',\n",
    "\t\tx=0.5, y=0.999)\n",
    "#plt.show()\n",
    "\n",
    "# Look at the distribution of quality by wine type\n",
    "red_wine = wine.ix[wine['type']=='red', 'quality']\n",
    "white_wine = wine.ix[wine['type']=='white', 'quality']\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "print(sns.distplot(red_wine, \\\n",
    "\t\tnorm_hist=True, kde=False, color=\"red\", label=\"Red wine\"))\n",
    "print(sns.distplot(white_wine, \\\n",
    "\t\tnorm_hist=True, kde=False, color=\"white\", label=\"White wine\"))\n",
    "sns.axlabel(\"Quality Score\", \"Density\")\n",
    "plt.title(\"Distribution of Quality by Wine Type\")\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "# Test whether mean quality is different between red and white wines\n",
    "print(wine.groupby(['type'])[['quality']].agg(['std', 'mean']))\n",
    "tstat, pvalue, df = sm.stats.ttest_ind(red_wine, white_wine)\n",
    "print('tstat: %.3f  pvalue: %.4f' % (tstat, pvalue))\n",
    "\n",
    "# Fit a multivariate linear regression model\n",
    "#wine_standardized = (wine - wine.mean()) / wine.std()\n",
    "#formula_all = 'quality ~ alcohol + chlorides + citric_acid + density + fixed_acidity + free_sulfur_dioxide + pH + residual_sugar + sulphates + total_sulfur_dioxide + volatile_acidity'\n",
    "my_formula = 'quality ~ alcohol + chlorides + citric_acid + density + fixed_acidity + free_sulfur_dioxide + pH + residual_sugar + sulphates + total_sulfur_dioxide + volatile_acidity'\n",
    "#formula_all = 'quality ~ fixed_acidity + volatile_acidity + citric_acid + residual_sugar + chlorides + free_sulfur_dioxide + total_sulfur_dioxide + density + pH + sulphates + alcohol'\n",
    "#formula = 'quality ~ residual_sugar + alcohol'\n",
    "lm = ols(my_formula, data=wine).fit()\n",
    "#lm = glm(my_formula, data=wine, family=sm.families.Gaussian()).fit()\n",
    "#lm = smf.glm(formula_all, data=wine_standardized, family=sm.families.Gaussian()).fit()\n",
    "print(lm.summary())\n",
    "print(\"\\nQuantities you can extract from the result:\\n%s\" % dir(lm))\n",
    "print(\"\\nCoefficients:\\n%s\" % lm.params)\n",
    "print(\"\\nCoefficient Std Errors:\\n%s\" % lm.bse)\n",
    "print(\"\\nAdj. R-squared:\\n%.2f\" % lm.rsquared_adj)\n",
    "print(\"\\nF-statistic: %.1f  P-value: %.2f\" % (lm.fvalue, lm.f_pvalue))\n",
    "print(\"\\nNumber of obs: %d  Number of fitted values: %s\" % (lm.nobs, len(lm.fittedvalues)))\n",
    "\n",
    "# Fit a multivariate linear model with standardized independent variables\n",
    "dependent_variable = wine['quality']\n",
    "independent_variables = wine[wine.columns.difference(['quality', 'type', 'in_sample'])]\n",
    "independent_variables_standardized = (independent_variables - independent_variables.mean()) / independent_variables.std()\n",
    "wine_standardized = pd.concat([dependent_variable, independent_variables_standardized], axis=1)\n",
    "lm_standardized = ols(my_formula, data=wine_standardized).fit()\n",
    "print(lm_standardized.summary())\n",
    "\n",
    "# Predict quality scores for \"new\" observations\n",
    "new_observations = wine.ix[wine.index.isin(xrange(10)), independent_variables.columns]\n",
    "y_predicted = lm.predict(new_observations)\n",
    "y_predicted_rounded = [round(score, 2) for score in y_predicted]\n",
    "print(y_predicted_rounded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 分組、色階分布圖與t檢定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 成對關係與相關性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 使用最小二平方估計法的線性迴歸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.5 解譯係數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.6 標準化自變數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.7 進行預測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Customer Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load statistics/customer_churn.py\n",
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Read the data set into a pandas DataFrame\n",
    "churn = pd.read_csv('churn.csv', sep=',', header=0)\n",
    "\n",
    "churn.columns = [heading.lower() for heading in \\\n",
    "churn.columns.str.replace(' ', '_').str.replace(\"\\'\", \"\").str.strip('?')]\n",
    "\n",
    "churn['churn01'] = np.where(churn['churn'] == 'True.', 1., 0.)\n",
    "print(churn.head())\n",
    "print(churn.describe())\n",
    "\n",
    "\n",
    "# Calculate descriptive statistics for grouped data\n",
    "print(churn.groupby(['churn'])[['day_charge', 'eve_charge', 'night_charge', 'intl_charge', 'account_length', 'custserv_calls']].agg(['count', 'mean', 'std']))\n",
    "\n",
    "# Specify different statistics for different variables\n",
    "print(churn.groupby(['churn']).agg({'day_charge' : ['mean', 'std'], \n",
    "\t\t\t\t'eve_charge' : ['mean', 'std'],\n",
    "\t\t\t\t'night_charge' : ['mean', 'std'],\n",
    "\t\t\t\t'intl_charge' : ['mean', 'std'],\n",
    "\t\t\t\t'account_length' : ['count', 'min', 'max'],\n",
    "\t\t\t\t'custserv_calls' : ['count', 'min', 'max']}))\n",
    "\n",
    "# Create total_charges, split it into 5 groups, and\n",
    "# calculate statistics for each of the groups\n",
    "churn['total_charges'] = churn['day_charge'] + churn['eve_charge'] + \\\n",
    "\t\t\t\t\t\t churn['night_charge'] + churn['intl_charge']\n",
    "factor_cut = pd.cut(churn.total_charges, 5, precision=2)\n",
    "def get_stats(group):\n",
    "\treturn {'min' : group.min(), 'max' : group.max(),\n",
    "\t\t\t'count' : group.count(), 'mean' : group.mean(),\n",
    "\t\t\t'std' : group.std()}\n",
    "grouped = churn.custserv_calls.groupby(factor_cut)\n",
    "print(grouped.apply(get_stats).unstack())\n",
    "\n",
    "# Split account_length into quantiles and\n",
    "# calculate statistics for each of the quantiles\n",
    "factor_qcut = pd.qcut(churn.account_length, [0., 0.25, 0.5, 0.75, 1.])\n",
    "grouped = churn.custserv_calls.groupby(factor_qcut)\n",
    "print(grouped.apply(get_stats).unstack())\n",
    "\n",
    "# Create binary/dummy indicator variables for intl_plan and vmail_plan\n",
    "# and join them with the churn column in a new DataFrame\n",
    "intl_dummies = pd.get_dummies(churn['intl_plan'], prefix='intl_plan')\n",
    "vmail_dummies = pd.get_dummies(churn['vmail_plan'], prefix='vmail_plan')\n",
    "churn_with_dummies = churn[['churn']].join([intl_dummies, vmail_dummies])\n",
    "print(churn_with_dummies.head())\n",
    "\n",
    "# Split total_charges into quartiles, create binary indicator variables\n",
    "# for each of the quartiles, and add them to the churn DataFrame\n",
    "qcut_names = ['1st_quartile', '2nd_quartile', '3rd_quartile', '4th_quartile']\n",
    "total_charges_quartiles = pd.qcut(churn.total_charges, 4, labels=qcut_names)\n",
    "dummies = pd.get_dummies(total_charges_quartiles, prefix='total_charges')\n",
    "churn_with_dummies = churn.join(dummies)\n",
    "print(churn_with_dummies.head())\n",
    "\n",
    "# Create pivot tables\n",
    "print(churn.pivot_table(['total_charges'], index=['churn', 'custserv_calls']))\n",
    "print(churn.pivot_table(['total_charges'], index=['churn'], columns=['custserv_calls']))\n",
    "print(churn.pivot_table(['total_charges'], index=['custserv_calls'], columns=['churn'], \\\n",
    "\t\t\t\t\t\taggfunc='mean', fill_value='NaN', margins=True))\n",
    "\n",
    "# Fit a logistic regression model\n",
    "dependent_variable = churn['churn01']\n",
    "independent_variables = churn[['account_length', 'custserv_calls', 'total_charges']]\n",
    "independent_variables_with_constant = sm.add_constant(independent_variables, prepend=True)\n",
    "logit_model = sm.Logit(dependent_variable, independent_variables_with_constant).fit()\n",
    "#logit_model = smf.glm(output_variable, input_variables, family=sm.families.Binomial()).fit()\n",
    "print(logit_model.summary())\n",
    "print(\"\\nQuantities you can extract from the result:\\n%s\" % dir(logit_model))\n",
    "print(\"\\nCoefficients:\\n%s\" % logit_model.params)\n",
    "print(\"\\nCoefficient Std Errors:\\n%s\" % logit_model.bse)\n",
    "#logit_marginal_effects = logit_model.get_margeff(method='dydx', at='overall')\n",
    "#print(logit_marginal_effects.summary())\n",
    "\n",
    "print(\"\\ninvlogit(-7.2205 + 0.0012*mean(account_length) + 0.4443*mean(custserv_calls) + 0.0729*mean(total_charges))\")\n",
    "\n",
    "def inverse_logit(model_formula):\n",
    "\tfrom math import exp\n",
    "\treturn (1.0 / (1.0 + exp(-model_formula)))*100.0\n",
    "\n",
    "at_means = float(logit_model.params[0]) + \\\n",
    "\tfloat(logit_model.params[1])*float(churn['account_length'].mean()) + \\\n",
    "\tfloat(logit_model.params[2])*float(churn['custserv_calls'].mean()) + \\\n",
    "\tfloat(logit_model.params[3])*float(churn['total_charges'].mean())\n",
    "\n",
    "print(churn['account_length'].mean())\n",
    "print(churn['custserv_calls'].mean())\n",
    "print(churn['total_charges'].mean())\n",
    "print(at_means)\n",
    "print(\"Probability of churn when independent variables are at their mean values: %.2f\" % inverse_logit(at_means))\n",
    "\n",
    "cust_serv_mean = float(logit_model.params[0]) + \\\n",
    "\tfloat(logit_model.params[1])*float(churn['account_length'].mean()) + \\\n",
    "\tfloat(logit_model.params[2])*float(churn['custserv_calls'].mean()) + \\\n",
    "\tfloat(logit_model.params[3])*float(churn['total_charges'].mean())\n",
    "\t\t\n",
    "cust_serv_mean_minus_one = float(logit_model.params[0]) + \\\n",
    "\t\tfloat(logit_model.params[1])*float(churn['account_length'].mean()) + \\\n",
    "\t\tfloat(logit_model.params[2])*float(churn['custserv_calls'].mean()-1.0) + \\\n",
    "\t\tfloat(logit_model.params[3])*float(churn['total_charges'].mean())\n",
    "\n",
    "print(cust_serv_mean)\n",
    "print(churn['custserv_calls'].mean()-1.0)\n",
    "print(cust_serv_mean_minus_one)\n",
    "print(\"Probability of churn when account length changes by 1: %.2f\" % (inverse_logit(cust_serv_mean) - inverse_logit(cust_serv_mean_minus_one)))\n",
    "\n",
    "# Predict churn for \"new\" observations\n",
    "new_observations = churn.ix[churn.index.isin(xrange(10)), independent_variables.columns]\n",
    "new_observations_with_constant = sm.add_constant(new_observations, prepend=True)\n",
    "y_predicted = logit_model.predict(new_observations_with_constant)\n",
    "y_predicted_rounded = [round(score, 2) for score in y_predicted]\n",
    "print(y_predicted_rounded)\n",
    "\n",
    "# Fit a logistic regression model\n",
    "output_variable = churn['churn01']\n",
    "vars_to_keep = churn[['account_length', 'custserv_calls', 'total_charges']]\n",
    "inputs_standardized = (vars_to_keep - vars_to_keep.mean()) / vars_to_keep.std()\n",
    "input_variables = sm.add_constant(inputs_standardized, prepend=False)\n",
    "logit_model = sm.Logit(output_variable, input_variables).fit()\n",
    "#logit_model = smf.glm(output_variable, input_variables, family=sm.families.Binomial()).fit()\n",
    "print(logit_model.summary())\n",
    "print(logit_model.params)\n",
    "print(logit_model.bse)\n",
    "#logit_marginal_effects = logit_model.get_margeff(method='dydx', at='overall')\n",
    "#print(logit_marginal_effects.summary())\n",
    "\n",
    "# Predict output value for a new observation based on its mean standardized input values\n",
    "input_variables = [0., 0., 0., 1.]\n",
    "predicted_value = logit_model.predict(input_variables)\n",
    "print(\"Predicted value: %.5f\") % predicted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
